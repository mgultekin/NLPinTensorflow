{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SequenceClassificationLstm.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPjErA4Yk44FM3pCoxX/4oj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgultekin/NLPinTensorflow/blob/main/SequenceClassificationLstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "058jkvctp81n"
      },
      "source": [
        "# Sequence Classification with LSTMs for IMDB movie review sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOW8jsPCocv4"
      },
      "source": [
        "#Author: MustafaGultekin\n",
        "#Purpose: Training with LSTM\n",
        "#resource: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pOuZzw0qQ-S"
      },
      "source": [
        "**Simple LSTM for Sequence Classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BeRQGa2qQod"
      },
      "source": [
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXECr79gosoQ",
        "outputId": "78512257-5a21-44ea-ffc9-4d982b368032"
      },
      "source": [
        "# lets load the dataset but keep the top n words, zero for the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBEV08rVugaG",
        "outputId": "722589b3-e118-456f-cb45-f22583bdd24b"
      },
      "source": [
        "X_train[0:3]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPHV9g37ulD3"
      },
      "source": [
        "#now we need to pad sequences for feeding model, they will have same size as length\n",
        "#model also will learn that zero values mean that nothing\n",
        "max_review_length = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXlBOwCzyYzw",
        "outputId": "cc1588c5-6461-4e45-b01b-126fc4e69763"
      },
      "source": [
        "X_train[0:3]\n",
        "print(len(X_train[0]))\n",
        "print(y_test[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YinzciEeyd8j",
        "outputId": "40ad68f7-f9ea-432c-dc70-b51804b8505f"
      },
      "source": [
        "#lets create the model\n",
        "#first layer is the emb. layer that uses 32 as length vectors to represent each word\n",
        "\n",
        "embedding_vector_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, embedding_vector_length, input_length = max_review_length ))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics =['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 3, batch_size = 64)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 50s 49ms/step - loss: 0.5862 - accuracy: 0.6674 - val_loss: 0.3793 - val_accuracy: 0.8467\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.3085 - accuracy: 0.8765 - val_loss: 0.3286 - val_accuracy: 0.8618\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.2466 - accuracy: 0.9047 - val_loss: 0.3452 - val_accuracy: 0.8584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8d472efd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rKw3sxd49hU",
        "outputId": "cef0670e-d36f-41db-b156-58cc76b33c59"
      },
      "source": [
        "#evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print('Accuracy: %', scores[1]*100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 10s 13ms/step - loss: 0.3452 - accuracy: 0.8584\n",
            "Accuracy: % 85.83999872207642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K6Xm4z-5VB5"
      },
      "source": [
        "**Lstm Model with Dropout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq8YyYNJ5PQK"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(top_words, embedding_vector_length, input_length= max_review_length))\n",
        "model2.add(LSTM(100))\n",
        "model2.add(Dropout(0.2))\n",
        "model2.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb5WCdj56Gms",
        "outputId": "de35ebf3-e7c2-4aaf-c717-98a739d448c5"
      },
      "source": [
        "model2.compile(loss='binary_crossentropy', optimizer = 'adam', metrics =['accuracy'])\n",
        "print(model2.summary())\n",
        "model2.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 3, batch_size = 64)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/3\n",
            "391/391 [==============================] - 21s 48ms/step - loss: 0.5939 - accuracy: 0.6504 - val_loss: 0.3874 - val_accuracy: 0.8359\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.2948 - accuracy: 0.8814 - val_loss: 0.3300 - val_accuracy: 0.8680\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 18s 47ms/step - loss: 0.2424 - accuracy: 0.9082 - val_loss: 0.3271 - val_accuracy: 0.8720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8d1253290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG26TzMF-I1J",
        "outputId": "59ba282a-6678-4e36-e7c4-d632c7558fed"
      },
      "source": [
        "#making prediction with our own sentences\n",
        "import keras as keras\n",
        "text = numpy.array(['this is a excellent movie'])\n",
        "#print(text.shape)\n",
        "tk = keras.preprocessing.text.Tokenizer( nb_words=2000, lower=True,split=' ')\n",
        "tk.fit_on_texts(text)\n",
        "prediction = model2.predict(numpy.array(tk.texts_to_sequences(text)))\n",
        "print(prediction)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.76749414]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3zQd_Np7eoZ",
        "outputId": "06c6338f-4f9b-4a79-a684-9b3db35ce7fa"
      },
      "source": [
        "#print(X_test[0])\n",
        "#pred = model2.predict(X_test[0])\n",
        "#print(y_test[0])\n",
        "#print(pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    1  591\n",
            "  202   14   31    6  717   10   10    2    2    5    4  360    7    4\n",
            "  177    2  394  354    4  123    9 1035 1035 1035   10   10   13   92\n",
            "  124   89  488    2  100   28 1668   14   31   23   27    2   29  220\n",
            "  468    8  124   14  286  170    8  157   46    5   27  239   16  179\n",
            "    2   38   32   25    2  451  202   14    6  717]\n",
            "0\n",
            "[[0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.44613928]\n",
            " [0.7743688 ]\n",
            " [0.42220291]\n",
            " [0.43893123]\n",
            " [0.44289544]\n",
            " [0.445621  ]\n",
            " [0.513029  ]\n",
            " [0.56239057]\n",
            " [0.52647245]\n",
            " [0.52647245]\n",
            " [0.49563837]\n",
            " [0.49563837]\n",
            " [0.549079  ]\n",
            " [0.5094519 ]\n",
            " [0.38857108]\n",
            " [0.499532  ]\n",
            " [0.5094519 ]\n",
            " [0.53027076]\n",
            " [0.49563837]\n",
            " [0.15172222]\n",
            " [0.6942066 ]\n",
            " [0.5094519 ]\n",
            " [0.47871888]\n",
            " [0.50856644]\n",
            " [0.2160577 ]\n",
            " [0.2160577 ]\n",
            " [0.2160577 ]\n",
            " [0.52647245]\n",
            " [0.52647245]\n",
            " [0.5088937 ]\n",
            " [0.4468604 ]\n",
            " [0.62133396]\n",
            " [0.5185044 ]\n",
            " [0.50274557]\n",
            " [0.49563837]\n",
            " [0.4021748 ]\n",
            " [0.46276513]\n",
            " [0.3854914 ]\n",
            " [0.44289544]\n",
            " [0.445621  ]\n",
            " [0.47573438]\n",
            " [0.5374809 ]\n",
            " [0.49563837]\n",
            " [0.55051273]\n",
            " [0.5206184 ]\n",
            " [0.4030107 ]\n",
            " [0.48827013]\n",
            " [0.62133396]\n",
            " [0.44289544]\n",
            " [0.38226342]\n",
            " [0.3624231 ]\n",
            " [0.48827013]\n",
            " [0.50390166]\n",
            " [0.5318206 ]\n",
            " [0.549079  ]\n",
            " [0.5374809 ]\n",
            " [0.49586138]\n",
            " [0.46539775]\n",
            " [0.58532065]\n",
            " [0.49563837]\n",
            " [0.48965776]\n",
            " [0.5196822 ]\n",
            " [0.6470648 ]\n",
            " [0.49563837]\n",
            " [0.5988872 ]\n",
            " [0.43893123]\n",
            " [0.44289544]\n",
            " [0.513029  ]\n",
            " [0.56239057]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX2n3RM49UGv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}