{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextGeneration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsLlWO5Gzpju7kBKwSzvts",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgultekin/NLPinTensorflow/blob/main/TextGeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLFIgIZH2HOh"
      },
      "source": [
        "#Author: MustafaGultekin\n",
        "#Purpose Practicing text generation with lstm through Project Gutenberg\n",
        "#source: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgf0MyHH333-"
      },
      "source": [
        "**Develop a Small LSTM Recurrent Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcyCif2B2c5S"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XUcVs0T2c7x"
      },
      "source": [
        "#load ascii text and convert it to lowercase\n",
        "filename = \"wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewbcIi4s2c-i"
      },
      "source": [
        "#we need to convert chars to integers, so were going to create a map of each charachter\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i,c in enumerate(chars))\n",
        "char_to_int"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_knGfOjq2dBC",
        "outputId": "8e2dc235-d32d-4037-a6f8-2557cb077cb0"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "\n",
        "print('Total characters: ', n_chars)\n",
        "print('Total vocab: ', n_vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total characters:  163779\n",
            "Total vocab:  58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqD-K1V52dDh",
        "outputId": "bf6c6c14-0d94-41ef-f4e2-c38352db2d15"
      },
      "source": [
        "# now we need to prepare data for training\n",
        "# we will split data into subsequences with a fixed length of 100characters\n",
        "\n",
        "#Each training pattern of the network is comprised of 100 timestemps of one charachter(X) followed by one character output\n",
        "#for example chapt e,  hapte  r   (for length 5)\n",
        "\n",
        "\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i: i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "\n",
        "print('Total patterns: ', len(dataX))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total patterns:  163679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ptl2_Sy_2dGB"
      },
      "source": [
        "# now we need to prepare our data into form of lstm which is [samples, timestamps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length,1))\n",
        "#normalize\n",
        "X = X / float(n_vocab)\n",
        "#one hot encode the ouput variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doxJ-Bg42dIy",
        "outputId": "c7e16ef3-887d-4824-af83-b4976cbe1ff6"
      },
      "source": [
        "X[0], y[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.81034483],\n",
              "        [0.84482759],\n",
              "        [0.79310345],\n",
              "        [0.70689655],\n",
              "        [0.62068966],\n",
              "        [0.5862069 ],\n",
              "        [0.87931034],\n",
              "        [0.01724138],\n",
              "        [0.65517241],\n",
              "        [0.89655172],\n",
              "        [0.87931034],\n",
              "        [0.62068966],\n",
              "        [0.77586207],\n",
              "        [0.56896552],\n",
              "        [0.62068966],\n",
              "        [0.84482759],\n",
              "        [0.65517241],\n",
              "        [0.12068966],\n",
              "        [0.86206897],\n",
              "        [0.01724138],\n",
              "        [0.55172414],\n",
              "        [0.74137931],\n",
              "        [0.68965517],\n",
              "        [0.5862069 ],\n",
              "        [0.62068966],\n",
              "        [0.12068966],\n",
              "        [0.86206897],\n",
              "        [0.01724138],\n",
              "        [0.55172414],\n",
              "        [0.60344828],\n",
              "        [0.9137931 ],\n",
              "        [0.62068966],\n",
              "        [0.77586207],\n",
              "        [0.87931034],\n",
              "        [0.89655172],\n",
              "        [0.84482759],\n",
              "        [0.62068966],\n",
              "        [0.86206897],\n",
              "        [0.01724138],\n",
              "        [0.68965517],\n",
              "        [0.77586207],\n",
              "        [0.01724138],\n",
              "        [0.93103448],\n",
              "        [0.79310345],\n",
              "        [0.77586207],\n",
              "        [0.60344828],\n",
              "        [0.62068966],\n",
              "        [0.84482759],\n",
              "        [0.74137931],\n",
              "        [0.55172414],\n",
              "        [0.77586207],\n",
              "        [0.60344828],\n",
              "        [0.18965517],\n",
              "        [0.01724138],\n",
              "        [0.56896552],\n",
              "        [0.96551724],\n",
              "        [0.01724138],\n",
              "        [0.74137931],\n",
              "        [0.62068966],\n",
              "        [0.93103448],\n",
              "        [0.68965517],\n",
              "        [0.86206897],\n",
              "        [0.01724138],\n",
              "        [0.5862069 ],\n",
              "        [0.55172414],\n",
              "        [0.84482759],\n",
              "        [0.84482759],\n",
              "        [0.79310345],\n",
              "        [0.74137931],\n",
              "        [0.74137931],\n",
              "        [0.        ],\n",
              "        [0.        ],\n",
              "        [0.87931034],\n",
              "        [0.67241379],\n",
              "        [0.68965517],\n",
              "        [0.86206897],\n",
              "        [0.01724138],\n",
              "        [0.62068966],\n",
              "        [0.56896552],\n",
              "        [0.79310345],\n",
              "        [0.79310345],\n",
              "        [0.72413793],\n",
              "        [0.01724138],\n",
              "        [0.68965517],\n",
              "        [0.86206897],\n",
              "        [0.01724138],\n",
              "        [0.63793103],\n",
              "        [0.79310345],\n",
              "        [0.84482759],\n",
              "        [0.01724138],\n",
              "        [0.87931034],\n",
              "        [0.67241379],\n",
              "        [0.62068966],\n",
              "        [0.01724138],\n",
              "        [0.89655172],\n",
              "        [0.86206897],\n",
              "        [0.62068966],\n",
              "        [0.01724138],\n",
              "        [0.79310345],\n",
              "        [0.63793103]]),\n",
              " array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCf1EkdF2dLD",
        "outputId": "7634c517-2a27-4db2-ecc0-629fe24a7132"
      },
      "source": [
        "#we can define lstm network now.\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEi5RpXbXa6i"
      },
      "source": [
        "\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD5zF-L1A23Z",
        "outputId": "f3aace58-46eb-4746-dc30-5e494127f403"
      },
      "source": [
        "model.fit(X,y, epochs = 20, batch_size= 128, callbacks=callbacks_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 1.7813\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.78125, saving model to weights-improvement-01-1.7813.hdf5\n",
            "Epoch 2/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 1.7760\n",
            "\n",
            "Epoch 00002: loss improved from 1.78125 to 1.77597, saving model to weights-improvement-02-1.7760.hdf5\n",
            "Epoch 3/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 1.7762\n",
            "\n",
            "Epoch 00003: loss did not improve from 1.77597\n",
            "Epoch 4/20\n",
            "1279/1279 [==============================] - 18s 14ms/step - loss: 1.7714\n",
            "\n",
            "Epoch 00004: loss improved from 1.77597 to 1.77139, saving model to weights-improvement-04-1.7714.hdf5\n",
            "Epoch 5/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7687\n",
            "\n",
            "Epoch 00005: loss improved from 1.77139 to 1.76871, saving model to weights-improvement-05-1.7687.hdf5\n",
            "Epoch 6/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7631\n",
            "\n",
            "Epoch 00006: loss improved from 1.76871 to 1.76311, saving model to weights-improvement-06-1.7631.hdf5\n",
            "Epoch 7/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7600\n",
            "\n",
            "Epoch 00007: loss improved from 1.76311 to 1.75999, saving model to weights-improvement-07-1.7600.hdf5\n",
            "Epoch 8/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7652\n",
            "\n",
            "Epoch 00008: loss did not improve from 1.75999\n",
            "Epoch 9/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7498\n",
            "\n",
            "Epoch 00009: loss improved from 1.75999 to 1.74983, saving model to weights-improvement-09-1.7498.hdf5\n",
            "Epoch 10/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7470\n",
            "\n",
            "Epoch 00010: loss improved from 1.74983 to 1.74703, saving model to weights-improvement-10-1.7470.hdf5\n",
            "Epoch 11/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7457\n",
            "\n",
            "Epoch 00011: loss improved from 1.74703 to 1.74565, saving model to weights-improvement-11-1.7457.hdf5\n",
            "Epoch 12/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7444\n",
            "\n",
            "Epoch 00012: loss improved from 1.74565 to 1.74436, saving model to weights-improvement-12-1.7444.hdf5\n",
            "Epoch 13/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7372\n",
            "\n",
            "Epoch 00013: loss improved from 1.74436 to 1.73723, saving model to weights-improvement-13-1.7372.hdf5\n",
            "Epoch 14/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7635\n",
            "\n",
            "Epoch 00014: loss did not improve from 1.73723\n",
            "Epoch 15/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7280\n",
            "\n",
            "Epoch 00015: loss improved from 1.73723 to 1.72801, saving model to weights-improvement-15-1.7280.hdf5\n",
            "Epoch 16/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7274\n",
            "\n",
            "Epoch 00016: loss improved from 1.72801 to 1.72744, saving model to weights-improvement-16-1.7274.hdf5\n",
            "Epoch 17/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7232\n",
            "\n",
            "Epoch 00017: loss improved from 1.72744 to 1.72317, saving model to weights-improvement-17-1.7232.hdf5\n",
            "Epoch 18/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7595\n",
            "\n",
            "Epoch 00018: loss did not improve from 1.72317\n",
            "Epoch 19/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7326\n",
            "\n",
            "Epoch 00019: loss did not improve from 1.72317\n",
            "Epoch 20/20\n",
            "1279/1279 [==============================] - 19s 15ms/step - loss: 1.7138\n",
            "\n",
            "Epoch 00020: loss improved from 1.72317 to 1.71378, saving model to weights-improvement-20-1.7138.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f466563c750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYZnAIT4Zwpl"
      },
      "source": [
        "**Generating Text with LSTM Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbPbF7dcBMWM"
      },
      "source": [
        "#load model weights\n",
        "filename = 'weights-improvement-20-1.7138.hdf5'\n",
        "model.load_weights(filename)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbT0gj88aEXX"
      },
      "source": [
        "#reverse mapping\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_-vOkPOaPxJ",
        "outputId": "0ab5be54-c284-44ae-8684-886635c47652"
      },
      "source": [
        "#pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX) - 1)\n",
        "pattern = dataX[start]\n",
        "print('seed:')\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "\n",
        "import sys\n",
        "#generate charachters\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose = 0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "seed:\n",
            "\" ime, and was a little\n",
            "startled when she heard her voice close to her ear. 'you're thinking\n",
            "about som \"\n",
            "e tome tome tome tome tome tome tome tome tome tome thme to the tares if the coor tiate whsh the toede of the coor, and the door tas a little soaeenly the coor of the court, and the door tas a little soaeenly the coor of the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a little soaeenly and the taid to the court, and the door tas a littl"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JriBqKBpdubD"
      },
      "source": [
        "#just an example for larger LSTM RNN\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}